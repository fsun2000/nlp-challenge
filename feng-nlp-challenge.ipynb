{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/fengyuansun/feng-nlp-challenge?scriptVersionId=136282592\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Import packages\nimport os\nimport os.path as osp \n\nimport re\nimport nltk\nimport string\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # fancier plotting\nimport matplotlib.pyplot as plt # plotting\n\nfrom tqdm import tqdm\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.model_selection import train_test_split\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize.casual import TweetTokenizer\n\n# nltk.download('omw-1.4')\n# nltk.download('wordnet')\n# nltk.download('wordnet2022')\n\n# ! cp -rf /usr/share/nltk_data/corpora/wordnet2022 /usr/share/nltk_data/corpora/wordnet # temp fix for lookup error.","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:44:29.024146Z","iopub.execute_input":"2023-07-06T13:44:29.024517Z","iopub.status.idle":"2023-07-06T13:44:29.871504Z","shell.execute_reply.started":"2023-07-06T13:44:29.024486Z","shell.execute_reply":"2023-07-06T13:44:29.870598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"display.max_colwidth\", 200) ","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:44:29.873278Z","iopub.execute_input":"2023-07-06T13:44:29.873614Z","iopub.status.idle":"2023-07-06T13:44:29.879929Z","shell.execute_reply.started":"2023-07-06T13:44:29.873585Z","shell.execute_reply":"2023-07-06T13:44:29.878912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n\"\"\"\n# Load training dataset\nfile_train = \"/kaggle/input/nlp-getting-started/train.csv\"\ndf = pd.read_csv(file_train)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:44:29.881851Z","iopub.execute_input":"2023-07-06T13:44:29.882322Z","iopub.status.idle":"2023-07-06T13:44:29.945499Z","shell.execute_reply.started":"2023-07-06T13:44:29.882292Z","shell.execute_reply":"2023-07-06T13:44:29.944645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Let's compare some negative and positive samples\npd.concat((df[df['target'] == 0][:5], df[df['target'] == 1][:5]))","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:44:29.947909Z","iopub.execute_input":"2023-07-06T13:44:29.948235Z","iopub.status.idle":"2023-07-06T13:44:29.965401Z","shell.execute_reply.started":"2023-07-06T13:44:29.948206Z","shell.execute_reply":"2023-07-06T13:44:29.964405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at dataset info\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:44:29.96691Z","iopub.execute_input":"2023-07-06T13:44:29.967247Z","iopub.status.idle":"2023-07-06T13:44:29.992249Z","shell.execute_reply.started":"2023-07-06T13:44:29.967217Z","shell.execute_reply":"2023-07-06T13:44:29.991323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Drop useless columns\n# df.drop(['id', 'keyword', 'location'], axis=1, inplace=True)\n# df.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:44:29.994335Z","iopub.execute_input":"2023-07-06T13:44:29.994889Z","iopub.status.idle":"2023-07-06T13:44:29.999224Z","shell.execute_reply.started":"2023-07-06T13:44:29.994859Z","shell.execute_reply":"2023-07-06T13:44:29.99822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing unwanted pattern from the tweets\ndef remove_pattern(text, pattern):\n    return re.sub(pattern, '', text)\n\n# Removing @\ndf['clean_tweet'] = np.vectorize(remove_pattern)(df['text'], r\"@[\\w]*\") \n\n# Removing #\ndf['clean_tweet'] = np.vectorize(remove_pattern)(df['clean_tweet'], r\"#\") \n\n# Removing hyperlinks\ndf['clean_tweet'] = np.vectorize(remove_pattern)(df['clean_tweet'], r'https?://\\S+')\n","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:44:30.00093Z","iopub.execute_input":"2023-07-06T13:44:30.002022Z","iopub.status.idle":"2023-07-06T13:44:30.076561Z","shell.execute_reply.started":"2023-07-06T13:44:30.001952Z","shell.execute_reply":"2023-07-06T13:44:30.075671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove words shorter than given length\nmin_word_len = 2 \ndf['clean_tweet'] = df['clean_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>min_word_len]))\n\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:44:30.106416Z","iopub.execute_input":"2023-07-06T13:44:30.106702Z","iopub.status.idle":"2023-07-06T13:44:30.151117Z","shell.execute_reply.started":"2023-07-06T13:44:30.106678Z","shell.execute_reply":"2023-07-06T13:44:30.150139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Spacy\nimport spacy\n\n# Load English language model\nnlp = spacy.load('en_core_web_sm')\n\ndef preprocess_spacy(text, nlp):\n    doc = nlp(text)\n    \n    # Remove stopwords and punctuation, and convert tokens to lowercase\n    tokens = [token.text.lower() for token in doc if not token.is_stop and not token.is_punct]\n    \n    return ' '.join(tokens)\n\ndf['clean_tweet'] = df['clean_tweet'].apply(preprocess_spacy, nlp=nlp)\n\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:44:30.278505Z","iopub.execute_input":"2023-07-06T13:44:30.278946Z","iopub.status.idle":"2023-07-06T13:45:34.631795Z","shell.execute_reply.started":"2023-07-06T13:44:30.278903Z","shell.execute_reply":"2023-07-06T13:45:34.63068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lemmatize_text(text):\n    doc = nlp(text)\n    lemmatized_text = ' '.join([token.lemma_ for token in doc])\n    return lemmatized_text\n\ndf['clean_tweet'] = df['clean_tweet'].apply(lemmatize_text)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:45:34.633943Z","iopub.execute_input":"2023-07-06T13:45:34.634818Z","iopub.status.idle":"2023-07-06T13:46:17.993993Z","shell.execute_reply.started":"2023-07-06T13:45:34.634783Z","shell.execute_reply":"2023-07-06T13:46:17.993049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = TweetTokenizer(preserve_case=False, \n                           reduce_len=True,\n                           strip_handles=True)\n\ndf['clean_tweet'] = df['clean_tweet'].apply(lambda x: tokenizer.tokenize(x))\ndf","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:46:17.99549Z","iopub.execute_input":"2023-07-06T13:46:17.995873Z","iopub.status.idle":"2023-07-06T13:46:18.69224Z","shell.execute_reply.started":"2023-07-06T13:46:17.995839Z","shell.execute_reply":"2023-07-06T13:46:18.691168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# WordCloud\nall_words = ' '.join([' '.join(l) for l in df['clean_tweet']]) \nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words) \nplt.figure(figsize=(10, 7)) \nplt.imshow(wordcloud, interpolation=\"bilinear\") \nplt.axis('off') \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:46:18.695118Z","iopub.execute_input":"2023-07-06T13:46:18.695476Z","iopub.status.idle":"2023-07-06T13:46:20.094664Z","shell.execute_reply.started":"2023-07-06T13:46:18.695445Z","shell.execute_reply":"2023-07-06T13:46:20.093821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Disaster tweets\n\nnegative_words = ' '.join([' '.join(l) for l in df['clean_tweet'][df['target'] == 1]]) \nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(negative_words)\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\") \nplt.axis('off') \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:46:20.095578Z","iopub.execute_input":"2023-07-06T13:46:20.095878Z","iopub.status.idle":"2023-07-06T13:46:21.139609Z","shell.execute_reply.started":"2023-07-06T13:46:20.095851Z","shell.execute_reply":"2023-07-06T13:46:21.138633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Non disaster tweets\n\nnormal_words =' '.join([' '.join(l) for l in df['clean_tweet'][df['target'] == 0]]) \nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(normal_words)\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\") \nplt.axis('off')\nplt.savefig('Non_disaster.png', bbox_inches='tight')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:46:21.140959Z","iopub.execute_input":"2023-07-06T13:46:21.141881Z","iopub.status.idle":"2023-07-06T13:46:22.44144Z","shell.execute_reply.started":"2023-07-06T13:46:21.141849Z","shell.execute_reply":"2023-07-06T13:46:22.440563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"short_words = [x for x in all_words.split() if len(x) < 3 ]\nprint(short_words[:10])\n        \n# Remove words shorter than given length\n# There are some new short utterances after tokenization. Most dont make sense\nmin_word_len = 2 \ndf['clean_tweet'] = df['clean_tweet'].apply(lambda x: ' '.join([w for w in x if len(w)>min_word_len]))\n\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:46:22.442893Z","iopub.execute_input":"2023-07-06T13:46:22.443538Z","iopub.status.idle":"2023-07-06T13:46:22.490379Z","shell.execute_reply.started":"2023-07-06T13:46:22.443505Z","shell.execute_reply":"2023-07-06T13:46:22.489263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Test:\n1. Compare 'raw' less processed sentences vs fully pre-processed sentences input to Embedding","metadata":{}},{"cell_type":"markdown","source":"# 5. Model Selection and Training\n   - Select appropriate machine learning models for text classification, such as Naive Bayes, Support Vector Machines (SVM), or deep learning models like Recurrent Neural Networks (RNNs) or Transformers.\n   - Split the preprocessed data into training and validation sets.\n   - Train the selected models using the training data and evaluate their performance using appropriate evaluation metrics.","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# fit model no training data\nmodel = XGBClassifier(n_estimators=1000, learning_rate=0.01, n_jobs=-1, \n                      early_stopping_rounds=5)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:46:22.49158Z","iopub.execute_input":"2023-07-06T13:46:22.492517Z","iopub.status.idle":"2023-07-06T13:46:22.629896Z","shell.execute_reply.started":"2023-07-06T13:46:22.492486Z","shell.execute_reply":"2023-07-06T13:46:22.629015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef train_model(X, y, X_val, y_val, model='SVC'):\n    if model == 'SVC':\n        model = SVC() \n        model.fit(X, y)\n    elif model == 'XGBClassifier':\n        model = XGBClassifier(n_estimators=1000, learning_rate=0.05, n_jobs=-1,\n                              early_stopping_rounds=5,\n                              max_depth=3)\n        model.fit(X, y, \n                  eval_set=[(X_val, y_val)],\n                  verbose=False)    \n    return model\n\ndef eval_model(model, X, y):\n    # Predict the labels for the training and testing data\n    y_pred = model.predict(X)\n    score = f1_score(y, y_pred)\n\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:46:22.63101Z","iopub.execute_input":"2023-07-06T13:46:22.631326Z","iopub.status.idle":"2023-07-06T13:46:22.638473Z","shell.execute_reply.started":"2023-07-06T13:46:22.631296Z","shell.execute_reply":"2023-07-06T13:46:22.637424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:46:22.641569Z","iopub.execute_input":"2023-07-06T13:46:22.642579Z","iopub.status.idle":"2023-07-06T13:46:37.216047Z","shell.execute_reply.started":"2023-07-06T13:46:22.642547Z","shell.execute_reply":"2023-07-06T13:46:37.214827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# K-fold cross validation\nfrom sklearn.model_selection import KFold\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.svm import SVC\n\n\nX = df['text']\ny = df['target']\nk = 5\nkf = KFold(n_splits=k, shuffle=True, random_state=42)\n\nembedding_model = SentenceTransformer('all-MiniLM-L6-v2')\nX_embeddings = embedding_model.encode(X.tolist())\n\ntrain_scores = []\nval_scores = []\nfor train_index, val_index in tqdm(kf.split(X_embeddings), total=k):\n    X_train, X_val = X_embeddings[train_index], X_embeddings[val_index]\n    y_train, y_val = y[train_index], y[val_index]\n    \n    # Perform model training and evaluation on the current fold\n    model = train_model(X_train, y_train, X_val, y_val, model=\"XGBClassifier\")\n    train_score = eval_model(model, X_train, y_train)\n    val_score = eval_model(model, X_val, y_val)\n    \n    # Store the validation score for the current fold\n    train_scores.append(train_score)\n    val_scores.append(val_score)\n\n# Print the scores for each fold\nfor fold in range(k):\n    print(f\"Fold {fold+1}: Train Score = {train_scores[fold]}\")\nprint(f\"Avg Train Score = {sum(train_scores) / len(train_scores)}\")\n    \nfor fold in range(k):\n    print(f\"Fold {fold+1}: Validation Score = {val_scores[fold]}\")\nprint(f\"Avg Validation Score = {sum(val_scores) / len(val_scores)}\")\n\n# Base XGBClassifier gives: \n# Avg Train Score = 0.9890328150989525\n# Avg Validation Score = 0.7744712508570869\n\n# Without GPU ~1:22 and ~2:58","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:46:37.217733Z","iopub.execute_input":"2023-07-06T13:46:37.218117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n\n# # Define the parameter grid\n# param_grid = {\n#     'max_depth': [3, 5, 7],\n#     'learning_rate': [0.1, 0.01],\n#     'n_estimators': [100, 200, 300],\n# }\n\n# # Create the XGBClassifier model\n# xgb_model = XGBClassifier()\n\n# # Perform grid search with cross-validation\n# grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=5)\n# grid_search.fit(X_embeddings, y)\n\n# # Get the best hyperparameter combination\n# best_params = grid_search.best_params_\n\n# X_train, X_test, y_train, y_test = train_test_split(X_embeddings, y, test_size=0.2, random_state=42)\n\n# # Train the final model using the best hyperparameters\n# final_model = XGBClassifier(**best_params)\n# final_model.fit(X_train, y_train)\n\n# # Evaluate the final model on the test set\n# y_pred = final_model.predict(X_test)\n# test_f1_score = f1_score(y, y_pred)\n\n# print(\"Best Hyperparameters:\", best_params)\n# print(\"Test F1-score:\", test_f1_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Idea's to further boost performance\n\n- There exists a small data imbalance between positive and negative samples. We could generate some positive samples using the synonym replacement method. Source: https://neptune.ai/blog/data-augmentation-nlp\n- feature engineering","metadata":{}},{"cell_type":"code","source":"### You can look into 'texthero' package for user-friendly preprocessing of text\n# example: https://www.kaggle.com/code/aravindanr22052001/stackoverflowrun/notebook","metadata":{"execution":{"iopub.execute_input":"2023-06-30T14:01:19.162376Z","iopub.status.busy":"2023-06-30T14:01:19.16135Z","iopub.status.idle":"2023-06-30T14:01:19.168408Z","shell.execute_reply":"2023-06-30T14:01:19.166846Z","shell.execute_reply.started":"2023-06-30T14:01:19.162326Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate submission","metadata":{}},{"cell_type":"code","source":"# # Load training dataset\n# sub_test = \"test.csv\"\n# sub_df = pd.read_csv(sub_test)\n# sub_df.drop(['keyword', 'location'], axis=1, inplace=True)\n\n# # pre-process text\n# corpus = preprocess_text(sub_df, stop=stopwords)\n# sub_df['text'] = [\" \".join(l) for l in corpus]\n\n# sub_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_df = df\n# sub_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load your sentence encoding model\n# embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n\n# # Encode the testing data\n# X_sub_embeddings = embedding_model.encode(sub_df['text'].tolist())\n\n# # y_sub_pred = model.predict(X_sub_embeddings)\n# y_sub_pred = predictor.predict(X_sub_embeddings)\n# y_sub_pred\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import csv\n\n# with open('submission.csv', 'w', newline='') as f:\n#     writer = csv.writer(f)\n    \n#     writer.writerow(['id','target'])\n    \n#     for i, j in zip(sub_df['id'].tolist(), y_sub_pred):\n#         writer.writerow([i, j])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(df['text'], df['target'], test_size=0.2, random_state=42)\n\n# Load your sentence encoding model\nembedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n\n# Encode the training and testing data\n# Takes ~1min on CPU\nX_train_embeddings = embedding_model.encode(X_train.tolist())\nX_test_embeddings = embedding_model.encode(X_test.tolist())","metadata":{"execution":{"iopub.status.busy":"2023-07-04T09:46:35.43579Z","iopub.status.idle":"2023-07-04T09:46:35.436346Z","shell.execute_reply":"2023-07-04T09:46:35.436092Z","shell.execute_reply.started":"2023-07-04T09:46:35.436066Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\n\ndef report_metrics(predictor, y_train, y_train_pred, y_test, y_test_pred):\n    # Report train and test statistics\n    train_report = classification_report(y_train, y_train_pred)\n    test_report = classification_report(y_test, y_test_pred)\n    test_accuracy = (y_test_pred == y_test).mean()\n\n    print(f\"Performance for {type(predictor).__name__}\")\n    print(\"Train Statistics:\")\n    print(train_report)\n    print(\"\\nTest Statistics:\")\n    print(test_report)\n\n    print(\"Test Accuracy:\", test_accuracy)\n\n\n# Select predictor type\nfor predictor in [SVC()]:   # LogisticRegression(), \n    \n    # Train a logistic regression classifier\n    classifier = predictor\n\n    classifier.fit(X_train_embeddings, y_train)\n\n    # Predict the labels for the training and testing data\n    y_train_pred = classifier.predict(X_train_embeddings)\n    y_test_pred = classifier.predict(X_test_embeddings)\n\n    # Get metrics\n    report_metrics(classifier, y_train, y_train_pred, y_test, y_test_pred)\n\n    \n\"\"\" Spacy, TweetTokenizer, and custom regex pre-processing\nPerformance for SVC\nTrain Statistics:\n              precision    recall  f1-score   support\n\n           0       0.89      0.96      0.92      3468\n           1       0.95      0.84      0.89      2622\n\n    accuracy                           0.91      6090\n   macro avg       0.92      0.90      0.91      6090\nweighted avg       0.91      0.91      0.91      6090\n\n\nTest Statistics:\n              precision    recall  f1-score   support\n\n           0       0.83      0.89      0.86       874\n           1       0.84      0.76      0.80       649\n\n    accuracy                           0.84      1523\n   macro avg       0.84      0.83      0.83      1523\nweighted avg       0.84      0.84      0.84      1523\n\nTest Accuracy: 0.8365068942875903\n\"\"\"\n\"\"\" with same processing steps\nPerformance for XGBClassifier\nTrain Statistics:\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99      3468\n           1       0.99      0.97      0.98      2622\n\n    accuracy                           0.98      6090\n   macro avg       0.99      0.98      0.98      6090\nweighted avg       0.98      0.98      0.98      6090\n\n\nTest Statistics:\n              precision    recall  f1-score   support\n\n           0       0.83      0.88      0.86       874\n           1       0.83      0.75      0.79       649\n\n    accuracy                           0.83      1523\n   macro avg       0.83      0.82      0.82      1523\nweighted avg       0.83      0.83      0.83      1523\n\nTest Accuracy: 0.8286277084701248\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-07-04T09:46:35.438476Z","iopub.status.idle":"2023-07-04T09:46:35.438957Z","shell.execute_reply":"2023-07-04T09:46:35.438755Z","shell.execute_reply.started":"2023-07-04T09:46:35.438736Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}